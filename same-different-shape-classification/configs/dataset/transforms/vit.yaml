train:
  _target_: torchvision.transforms.v2.Compose
  transforms: 
      - _target_: torchvision.transforms.v2.Resize
        size: 256
        antialias: True
      - _target_: torchvision.transforms.v2.CenterCrop
        size: 224
      - _target_: torchvision.transforms.v2.RandomRotation
        degrees: [0., 360.]
        fill: 1.
      - _target_: torchvision.transforms.v2.Normalize
        mean: [0.485, 0.456, 0.406]
        std: [0.229, 0.224, 0.225]


inference:
  _target_: torchvision.transforms.v2.Compose
  transforms: 
      - _target_: torchvision.transforms.v2.Resize
        size: 256
        antialias: True
      - _target_: torchvision.transforms.v2.CenterCrop
        size: 224
      - _target_: torchvision.transforms.v2.Normalize
        mean: [0.485, 0.456, 0.406]
        std: [0.229, 0.224, 0.225]